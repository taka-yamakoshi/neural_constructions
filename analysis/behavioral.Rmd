---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(tidyboot)
library(ggthemes)
```

Import data

```{r}
d_raw <- read_csv('../data/dataFromMongo.csv')
```

Implement exclusion criteria

```{r}
complete_games <- d_raw %>%
  filter(stimulus_type == 'main_judgement') %>%
  group_by(gameid) %>%
  tally() %>%
  filter(n == 50) %>%
  pull(gameid) 

failed_quiz <- d_raw %>%
  group_by(gameid) %>% 
  tally() %>% 
  filter(n == 5) %>% 
  pull(gameid)

# Exclude participants who fail either catch trial
failed_catch_trials <- d_raw %>%
  filter(stimulus_type %in% c('catch1', 'catch2')) %>%
  mutate(errorPreference = ifelse(highValueMeans == 'error', 
                                  response, 100-response)) %>%
  filter(errorPreference > 50) %>%
  pull(gameid) %>%
  unique()
  
# Exclude all data from participants who skipped through >50% of trials
failed_rt_check <- d_raw %>%
  filter(stimulus_type == 'main_judgement') %>%
  filter(gameid %in% complete_games) %>%
  mutate(rt_below_threshold = rt < 3000) %>%
  group_by(gameid, rt_below_threshold) %>%
  tally() %>%
  spread(rt_below_threshold, n) %>%
  mutate(proportion_guessed = `TRUE`/(`TRUE` + `FALSE`)) %>%
  filter(proportion_guessed > 0.25) %>%
  pull(gameid)

ids_to_exclude <- unique(c(failed_rt_check, failed_catch_trials))
cat("excluding ", length(ids_to_exclude), "/", length(complete_games))
```

```{r}
d_judgements <- d_raw %>%
  filter(gameid %in% complete_games) %>%
  # Remove all excluded participants
  filter(!(gameid %in% ids_to_exclude)) %>%
  filter(stimulus_type == 'main_judgement') %>%
  # Also exclude particular trials that we under reading rt threshold
  filter(rt > 3000) %>%
  # Re-map randomized A/B assignment so that high always means DO
  mutate(DOpreference = ifelse(highValueMeans == 'DO', 
                               response, 100 - response),
         recipient_id = factor(recipient_id), 
         theme_type = factor(theme_type),
         verb = word(DOsentence, 2)) %>%
  rename(participant_id = gameid,
         set_id = setid) %>%
  select(-response, -responses,-stimulus_type,-iterationName,-highValueMeans)

write_csv(d_judgements, '../data/data_cleaned.csv')
```

due to dropout and catch trial failures, we didn't get the same number of participants for all of the trial sets.

however, every set was seen at least 5 times, and the average was 10 times.

```{r}
d_judgements %>% group_by(participant_id, set_id) %>% tally() %>% group_by(set_id) %>% tally() %>%
  ggplot(aes(x = n)) +
  geom_histogram() +
  theme_few()
```

Collapse over everything and look at alternating vs. non-alternating.

```{r}
d_judgements %>%
  group_by(classification) %>%
  tidyboot_mean(DOpreference, nboot = 100) %>%
  ggplot(aes(x = classification, y = empirical_stat)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    labs(x = 'verb class', y = 'average DO preference') +
    theme_few() 
```

Break out by recipient_id.

```{r}
d_judgements %>%
  group_by(classification, recipient_id) %>%
  tidyboot_mean(DOpreference, nboot = 100) %>%
  mutate(recipient_id = fct_reorder(recipient_id, empirical_stat)) %>%
  ggplot(aes(x = classification, y = empirical_stat)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    labs(x = 'verb class', y = 'average DO preference') +
    guides(x = guide_axis(angle = 90)) +
    facet_grid( ~ recipient_id) +
    theme_few() +
    theme(aspect.ratio = 2)

ggsave("recipient_type.pdf")
```

Break out by verb.

```{r}
d_judgements %>%
  filter(recipient_id == 'pronoun') %>%
  mutate(split = ifelse(row_number() < length(verb)/2,
                        'split1', 'split2')) %>%
  group_by(split, verb, classification) %>%
  tidyboot_mean(DOpreference, nboot = 100) %>%
  group_by(verb) %>%
  mutate(grand_avg = mean(empirical_stat)) %>%
  ungroup() %>%
  mutate(verb = fct_reorder(verb, grand_avg)) %>%
  group_by(split) %>%
  ggplot(aes(x = verb, y = empirical_stat, fill = classification)) +
    geom_bar(stat = 'identity') +
    geom_hline(yintercept = 50, linetype = 'dotted') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    labs(x = '', y = 'average DO preference') +
    guides(x = guide_axis(n.dodge = 2, angle = 90)) +
    facet_grid(split ~ ., scales = 'free_x') +
    theme_few() +
    theme(aspect.ratio = 1/10)

ggsave("verbs_aggregated_split.pdf", width = 20, height = 7, units = 'in')
```

Cross-validate rater agreement for verb ranking?

```{r}
smp_size <- floor(0.5 * nrow(d_judgements))

map_dbl(1:100, ~ {
  d_judgements %>%
    #filter(recipient_id == 'pronoun') %>%
    sample_frac(1) %>%
    mutate(split = row_number() < smp_size) %>%
    group_by(verb, split) %>%
    summarize(DOpreference = mean(DOpreference)) %>%
    spread(split, DOpreference) %>%
    ungroup() %>%
    summarize(c = cor(`TRUE`, `FALSE`, method = 'spearman')) %>%
    pull(c)
}) %>%
  qplot() + theme_few()
```

How often do people rate DO as better?

```{r}
d_judgements %>%
  group_by(classification, recipient_id) %>%
  summarize(pct_DO_better = mean(DOpreference_binary))
```
