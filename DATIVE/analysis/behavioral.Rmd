---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(tidyboot)
library(lme4)
library(ggthemes)
```

Import data

```{r}
d_raw <- read_csv('../data/experiment_output/dataFromMongo.csv')
```

Implement exclusion criteria

```{r}
complete_games <- d_raw %>%
  filter(stimulus_type == 'main_judgement') %>%
  group_by(gameid) %>%
  tally() %>%
  filter(n == 50) %>%
  pull(gameid) 

failed_quiz <- d_raw %>%
  group_by(gameid) %>% 
  tally() %>% 
  filter(n == 5) %>% 
  pull(gameid)

# Exclude participants who fail either catch trial
failed_catch_trials <- d_raw %>%
  filter(stimulus_type %in% c('catch1', 'catch2')) %>%
  mutate(errorPreference = ifelse(highValueMeans == 'error', 
                                  response, 100-response)) %>%
  filter(errorPreference > 50) %>%
  pull(gameid) %>%
  unique()
  
# Exclude all data from participants who skipped through >50% of trials
failed_rt_check <- d_raw %>%
  filter(stimulus_type == 'main_judgement') %>%
  filter(gameid %in% complete_games) %>%
  mutate(rt_below_threshold = rt < 3000) %>%
  group_by(gameid, rt_below_threshold) %>%
  tally() %>%
  spread(rt_below_threshold, n) %>%
  mutate(proportion_guessed = `TRUE`/(`TRUE` + `FALSE`)) %>%
  filter(proportion_guessed > 0.25) %>%
  pull(gameid)

ids_to_exclude <- unique(c(failed_rt_check, failed_catch_trials))
cat("excluding ", length(ids_to_exclude), "/", length(complete_games))
```

```{r}
d_judgements <- d_raw %>%
  filter(gameid %in% complete_games) %>%
  # Remove all excluded participants
  filter(!(gameid %in% ids_to_exclude)) %>%
  filter(stimulus_type == 'main_judgement') %>%
  # Also exclude particular trials that we under reading rt threshold
  filter(rt > 3000) %>%
  # Re-map randomized A/B assignment so that high always means DO
  mutate(DOpreference = ifelse(highValueMeans == 'DO', 
                               response, 100 - response),
         recipient_id = factor(recipient_id), 
         theme_type = factor(theme_type),
         theme_type = fct_collapse(theme_type, indef = c('indef', 'something'), def = c('def')),
         verb = word(DOsentence, 2)) %>%
  rename(participant_id = gameid,
         set_id = setid) %>%
  select(-response, -responses,-stimulus_type,-iterationName,-highValueMeans)

write_csv(d_judgements, '../data/experiment_output/data_cleaned.csv')
```

```{r}
cat(d_judgements %>% pull(participant_id) %>% unique() %>% length(), 'participants')
cat(d_judgements %>% pull(participant_id) %>% length(), 'judgements')

```

due to dropout and catch trial failures, we didn't get the same number of participants for all of the trial sets.

however, every set was seen at least 5 times, and the average was 10 times.

```{r}
d_judgements %>% group_by(participant_id, set_id) %>% tally() %>% group_by(set_id) %>% tally() %>%
  ggplot(aes(x = n)) +
  geom_histogram() +
  theme_few()
```

Collapse over everything and look at alternating vs. non-alternating.

```{r}
d_judgements %>%
  group_by(classification) %>%
  tidyboot_mean(DOpreference, nboot = 100) %>%
  ggplot(aes(x = classification, y = empirical_stat)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    labs(x = 'verb class', y = 'average DO preference') +
    theme_few() 
```

```{r}
library(lmerTest)
d_judgements %>%
  lmer(DOpreference ~ classification + (1 + classification| participant_id),
       data = .,
      control = lmerControl(calc.derivs = FALSE)) %>%
  summary()
```

Break out by recipient_id.

```{r}
d_judgements %>%
  group_by(classification, theme_type, recipient_id) %>%
  tidyboot_mean(DOpreference - 50, nboot = 1000) %>%
  ungroup() %>%
  mutate(recipient_id = fct_reorder(recipient_id, empirical_stat),
        classification = fct_relevel(classification, 'non-alternating')) %>%
  ggplot(aes(x = recipient_id,  y = empirical_stat, fill = theme_type)) +
    geom_bar(stat = 'identity', position=position_dodge(width = 0.9)) +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0, position=position_dodge(width = 0.9)) +
    labs(x = 'recipient type', y = 'average DO preference') +
    guides(x = guide_axis(angle = 90)) +
    scale_fill_colorblind()+
    facet_wrap(~classification) +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = 'top')

ggsave("../../neural_constructions_tex/figs/appendix_recipient_type.pdf", width = 3.5, height=3.5, units = 'in')
```

Compute statistics. We code 'pronoun' as a kind of definite. The maximal random effect structure containing random slopes for theme_type did not converge.

```{r}
library(lme4)
library(lmerTest)
library(broom.mixed)
human.lme <- d_judgements %>%
  mutate(recipient_id = case_when(
    recipient_id == 'shortDefinite' ~ 'short_definite',
    recipient_id == 'longDefinite' ~ 'long_definite',
    recipient_id == 'shortIndefinite' ~ 'short_indefinite',
    recipient_id == 'longIndefinite' ~ 'long_indefinite',
    recipient_id == 'pronoun' ~ 'extrashort_definite')
  ) %>%
  separate(recipient_id, 
           into = c('recipient_length', 'recipient_definiteness'), 
           sep='_') %>%
  lmer(DOpreference ~ recipient_length + recipient_definiteness + theme_type
                      + (1 + recipient_length + recipient_definiteness| participant_id) 
                      + (1 + recipient_length + recipient_definiteness| verb), 
       data = .,
      control = lmerControl(calc.derivs = FALSE)) 

human.lme %>%
  tidy() %>%
  xtable()
```

Break out by verb.

```{r}
d_judgements %>%
  filter(recipient_id == 'pronoun') %>%
  group_by(verb, classification) %>%
  tidyboot_mean(DOpreference, nboot = 1) %>%
  group_by(verb) %>%
  mutate(grand_avg = mean(empirical_stat)) %>%
  ungroup() %>%
  mutate(verb = fct_reorder(verb, grand_avg)) %>%
  ggplot(aes(x = verb, y = empirical_stat, fill = classification)) +
    geom_bar(stat = 'identity') +
    geom_hline(yintercept = 50, linetype = 'dotted') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    labs(x = '', y = 'average DO preference') +
    guides(x = guide_axis(n.dodge = 1, angle = 90, check.overlap = T)) +
    theme_few() +
    theme(aspect.ratio = 1/10, legend.position = 'top')

ggsave("../../neural_constructions_tex/figs/verbs_aggregated.pdf", width = 10, height = 3, units = 'in')
```

Cross-validate rater agreement for verb ranking?

```{r}
smp_size <- floor(0.5 * nrow(d_judgements))

agreement.out <- map_dbl(1:100, ~ {
  d_judgements %>%
    sample_frac(1) %>%
    mutate(split = row_number() < smp_size) %>%
    group_by(verb, split) %>%
    summarize(DOpreference = mean(DOpreference)) %>%
    spread(split, DOpreference) %>%
    ungroup() %>%
    summarize(c = cor(`TRUE`, `FALSE`, method = 'spearman')) %>%
    pull(c)
}) 

cat(mean(agreement.out))
```

### Look at frequency effects

```{r}
d_judgements %>%
  filter(recipient_id == 'pronoun') %>%
  group_by(verb, frequency_rank, classification) %>%
  tidyboot_mean(DOpreference, nboot = 100) %>%
  ggplot(aes(x = frequency_rank, y = empirical_stat, color = classification)) +
    geom_point(alpha = 0.5) +
    geom_hline(yintercept = 50, linetype = 'dotted') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    geom_smooth(method = 'lm') +
    labs(x = 'frequency (rank)', y = 'average DO preference') +
    guides(x = guide_axis(n.dodge = 1, angle = 90, check.overlap = T)) +
    theme_few() +
    theme(legend.position = 'top')

ggsave("frequency-effects.pdf")
```

## Sanity checks

How often do people rate DO as absolutely better? (i.e. >50%)

```{r}
d_judgements %>%
  group_by(classification, recipient_id) %>%
  summarize(pct_DO_better = mean(DOpreference_binary))
```

```{r}
d_judgements %>%
  filter(recipient_id == 'pronoun') %>%
  mutate(split = ifelse(row_number() < length(verb)/2,
                        'split1', 'split2')) %>%
  group_by(split, verb, classification) %>%
  tidyboot_mean(DOpreference, nboot = 100) %>%
  group_by(verb) %>%
  mutate(grand_avg = mean(empirical_stat)) %>%
  ungroup() %>%
  mutate(verb = fct_reorder(verb, grand_avg)) %>%
  group_by(split) %>%
  ggplot(aes(x = verb, y = empirical_stat, fill = classification)) +
    geom_bar(stat = 'identity') +
    geom_hline(yintercept = 50, linetype = 'dotted') +
    geom_errorbar(aes(ymin = ci_lower, ymax=ci_upper), width = 0) +
    labs(x = '', y = 'average DO preference') +
    guides(x = guide_axis(n.dodge = 2, angle = 90)) +
    facet_grid(split ~ ., scales = 'free_x') +
    theme_few() +
    theme(aspect.ratio = 1/10)

ggsave("verbs_aggregated_split.pdf", width = 20, height = 7, units = 'in')
```